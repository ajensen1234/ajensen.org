@article{burtonAutomaticTrackingHealthy2021,
  title = {Automatic Tracking of Healthy Joint Kinematics from Stereo-Radiography Sequences.},
  author = {Burton, William and Jensen, Andrew and Myers, Casey A. and Hamilton, Landon and Shelburne, Kevin B. and Banks, Scott A. and Rullkoetter, Paul J.},
  year = {2021},
  journal = {Computers in Biology and Medicine},
  doi = {10.1016/j.compbiomed.2021.104945},
  abstract = {Kinematic tracking of healthy joints in radiography sequences is frequently performed by maximizing similarities between computed perspective projections of 3D computer models and corresponding objects' appearances in radiographic images. Significant human effort associated with manual tracking presents a major bottleneck in biomechanics research methods and limits the scale of target applications. The current work introduces a method for fully-automatic tracking of tibiofemoral and patellofemoral kinematics in stereo-radiography sequences for subjects performing dynamic activities. The proposed method involves the application of convolutional neural networks for annotating radiographs and a multi-stage optimization pipeline for estimating bone pose based on information provided by neural net predictions. Predicted kinematics are evaluated by comparing against manually-tracked trends across 20 distinct trials. Median absolute differences below 1.5millimeters or degrees for 6 tibiofemoral and 3 patellofemoral degrees of freedom demonstrate the utility of our approach, which improves upon previous semi-automatic methods by enabling end-to-end automation. Implementation of a fully-automatic pipeline for kinematic tracking will benefit evaluation of human movement by enabling large-scale studies of healthy knee kinematics.},
  pmid = {34678483},
  annotation = {MAG ID: 3206636315},
  file = {C\:\\Users\\ajensen123\\Zotero\\storage\\KLSW4ABE\\Burton et al. - 2021 - Automatic tracking of healthy joint kinematics fro.pdf}
}

@article{jensenJointTrackMachine2022,
  title = {Joint {{Track Machine Learning}}: {{An}} Autonomous Method for Measuring {{6DOF TKA}} Kinematics from Single-Plane x-Ray Images},
  shorttitle = {Joint {{Track Machine Learning}}},
  author = {Jensen, Andrew and Flood, Paris and {Palm-Vlasak}, Lindsey and Burton, Will and Rullkoetter, Paul and Banks, Scott},
  year = {2022},
  month = apr,
  journal = {arXiv:2205.00057 [q-bio]},
  eprint = {2205.00057},
  eprinttype = {arxiv},
  primaryclass = {q-bio},
  abstract = {Dynamic radiographic measurement of 3D TKA kinematics has provided important information for implant design and surgical technique for over 30 years. However, current methods of measuring TKA kinematics are too cumbersome or time-consuming for practical clinical application. Even stateof-the-art techniques require human-supervised initialization or human supervision throughout the entire optimization process. Elimination of human supervision could potentially bring this technology into clinical practicality. Therefore, we propose a fully autonomous pipeline for quantifying TKA kinematics from single-plane imaging. First, a convolutional neural network segments the femoral and tibial implants from the image. Second, segmented images are compared to Normalized Fourier Descriptor shape libraries for initial pose estimates. Lastly, a Lipschitzian optimization routine minimizes the difference between the segmented image and the projected implant. This technique reliably reproduces human-supervised kinematics measurements from internal datasets and external validation studies, with RMS differences of less than 0.7mm and 4\textdegree{} for internal studies and 0.8mm and 1.7\textdegree{} for external validation studies. This performance indicates that it will soon be practical to perform these measurements in a clinical setting.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Quantitative Biology - Quantitative Methods},
  file = {C\:\\Users\\ajensen123\\Zotero\\storage\\SPR9P82A\\Jensen et al. - 2022 - Joint Track Machine Learning An autonomous method.pdf}
}
